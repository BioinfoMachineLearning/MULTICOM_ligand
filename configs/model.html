<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />

        <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            
            gtag('config', '');
            
        </script>
    <meta property="og:title" content="Model" />
<meta property="og:type" content="website" />
<meta property="og:url" content="configs/model.html" />
<meta property="og:site_name" content="MULTICOM_ligand" />
<meta property="og:description" content="This section describes the configurations for various method-related scripts. Method inference: These configurations are used to specify how inference is performed with each method. DiffDock infere..." />
<meta property="og:image:width" content="1146" />
<meta property="og:image:height" content="600" />
<meta property="og:image" content="_images/social_previews/summary_configs_model_5bca2693.png" />
<meta property="og:image:alt" content="This section describes the configurations for various method-related scripts. Method inference: These configurations are used to specify how inference is performed with each method. DiffDock infere..." />
<meta name="description" content="This section describes the configurations for various method-related scripts. Method inference: These configurations are used to specify how inference is performed with each method. DiffDock infere..." />
<meta name="twitter:card" content="summary_large_image" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Binding site crop preparation" href="../modules/multicom_ligand.binding_site_crop_preparation.html" /><link rel="prev" title="Data" href="data.html" />
        <link rel="prefetch" href="../_static/WorkBench.jpeg" as="image" />

    <!-- Generated with Sphinx 7.4.7 and Furo 2025.07.19 -->
        <title>Model - MULTICOM_ligand 0.4.0</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=25af2a20" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-codeautolink.css?v=125d5c1c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">MULTICOM_ligand 0.4.0</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/WorkBench.jpeg" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">MULTICOM_ligand 0.4.0</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html#dynamicbind-checkpoint-0-25-gb">DynamicBind checkpoint (~0.25 GB)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html#rosettafold-all-atom-checkpoint-1-5-gb">RoseTTAFold-All-Atom checkpoint (~1.5 GB)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data_preparation.html">How to prepare <cite>MULTICOM_ligand</cite> data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../available_methods.html">Available inference methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../method_inference.html">How to run inference with individual methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ensemble_inference.html">How to run inference with a method ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ensemble_inference.html#note-the-suffixes-for-both-output-dir-and-ensemble-benchmarking-repeat-index-should-be-modified-to-e-g-2-3">NOTE: the suffixes for both <code class="docutils literal notranslate"><span class="pre">output_dir</span></code> and <code class="docutils literal notranslate"><span class="pre">ensemble_benchmarking_repeat_index</span></code> should be modified to e.g., 2, 3, …</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ensemble_inference.html#benchmark-using-the-posebusters-benchmark-dataset-e-g-after-generating-40-complexes-per-target-with-each-method">benchmark using the PoseBusters Benchmark dataset e.g., after generating 40 complexes per target with each method</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ensemble_inference.html#benchmark-using-the-astex-diverse-dataset-e-g-after-generating-40-complexes-per-target-with-each-method">benchmark using the Astex Diverse dataset e.g., after generating 40 complexes per target with each method</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ensemble_inference.html#benchmark-using-the-dockgen-dataset-e-g-after-generating-40-complexes-per-target-with-each-method">benchmark using the DockGen dataset e.g., after generating 40 complexes per target with each method</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ensemble_inference.html#benchmark-using-the-casp15-dataset-e-g-after-generating-40-complexes-per-target-with-each-method">benchmark using the CASP15 dataset e.g., after generating 40 complexes per target with each method</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ensemble_inference.html#analyze-benchmarking-results-for-the-posebusters-benchmark-dataset">analyze benchmarking results for the PoseBusters Benchmark dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../comparative_plots.html">How to create comparative plots of inference results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../comparative_plots.html#analyze-benchmarking-results-for-the-casp15-dataset">analyze benchmarking results for the CASP15 dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../for_developers.html">For developers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../acknowledgements.html">Acknowledgements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../citing_this_work.html">Citing this work</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bonus.html">Bonus</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Default Configs</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="analysis.html">Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">Data</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules/multicom_ligand.binding_site_crop_preparation.html">Binding site crop preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/multicom_ligand.complex_alignment.html">Complex alignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/multicom_ligand.inference_relaxation.html">Inference relaxation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/multicom_ligand.minimize_energy.html">Minimize energy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/multicom_ligand.ensemble_generation.html">Ensemble generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/multicom_ligand.data_utils.html">Data utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/multicom_ligand.model_utils.html">Model utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/multicom_ligand.utils.html">General utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/multicom_ligand.resolvers.html">OmegaConf resolvers</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/configs/model.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="model">
<h1>Model<a class="headerlink" href="#model" title="Link to this heading">¶</a></h1>
<p>This section describes the configurations for various method-related scripts.</p>
<section id="method-inference">
<h2>Method inference<a class="headerlink" href="#method-inference" title="Link to this heading">¶</a></h2>
<p>These configurations are used to specify how inference is performed with each method.</p>
<section id="diffdock-inference">
<h3>DiffDock inference<a class="headerlink" href="#diffdock-inference" title="Link to this heading">¶</a></h3>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text"><code class="file docutils literal notranslate"><span class="pre">model/diffdock_inference.yaml</span></code></span><a class="headerlink" href="#id1" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">cuda_device_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the CUDA device to use for inference, or `null` to use CPU</span>
<span class="nt">python_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock/DiffDock/bin/python3</span><span class="w"> </span><span class="c1"># the Python executable to use</span>
<span class="nt">diffdock_exec_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock</span><span class="w"> </span><span class="c1"># the DiffDock directory in which to execute the inference scripts</span>
<span class="nt">dataset</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">posebusters_benchmark</span><span class="w"> </span><span class="c1"># the dataset to use - NOTE: must be one of (`posebusters_benchmark`, `astex_diverse`, `dockgen`, `casp15`)</span>
<span class="nt">input_csv_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock/inference/diffdock_${dataset}_inputs.csv</span><span class="w"> </span><span class="c1"># the input CSV filepath with which to run inference</span>
<span class="nt">inference_config_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock/default_inference_args.yaml</span><span class="w"> </span><span class="c1"># the inference configuration file to use</span>
<span class="nt">output_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock/inference/diffdock_${dataset}_output_${repeat_index}</span><span class="w"> </span><span class="c1"># the output directory to which to save the inference results</span>
<span class="nt">model_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock/workdir/v1.1/score_model</span><span class="w"> </span><span class="c1"># the directory in which the trained model is saved</span>
<span class="nt">confidence_model_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock/workdir/v1.1/confidence_model</span><span class="w"> </span><span class="c1"># the directory in which the trained confidence model is saved</span>
<span class="nt">inference_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20</span><span class="w"> </span><span class="c1"># the maximum number of inference (reverse diffusion) steps to run</span>
<span class="nt">samples_per_complex</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40</span><span class="w"> </span><span class="c1"># the number of samples to generate per complex</span>
<span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w"> </span><span class="c1"># the batch size to use for inference</span>
<span class="nt">actual_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">19</span><span class="w"> </span><span class="c1"># the actual number of inference steps to run (i.e., after how many steps to halt the reverse diffusion process)</span>
<span class="nt">no_final_step_noise</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to disable the final inference step&#39;s noise from being added</span>
<span class="nt">repeat_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the repeat index to use for inference</span>
<span class="nt">skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to skip inference for existing output directories</span>
<span class="nt">max_num_inputs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># if provided, the number of (dataset subset) inputs over which to run inference</span>
</pre></div>
</div>
</div>
</section>
<section id="fabind-inference">
<h3>FABind inference<a class="headerlink" href="#fabind-inference" title="Link to this heading">¶</a></h3>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text"><code class="file docutils literal notranslate"><span class="pre">model/fabind_inference.yaml</span></code></span><a class="headerlink" href="#id2" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">cuda_device_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the CUDA device to use for inference, or `null` to use CPU</span>
<span class="nt">python_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/FABind/FABind/bin/python3</span><span class="w"> </span><span class="c1"># the Python executable to use</span>
<span class="nt">fabind_exec_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/FABind/fabind</span><span class="w"> </span><span class="c1"># the FABind directory in which to execute the inference scripts</span>
<span class="nt">dataset</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">posebusters_benchmark</span><span class="w"> </span><span class="c1"># the dataset to use - NOTE: must be one of (`posebusters_benchmark`, `astex_diverse`, `dockgen`, `casp15`)</span>
<span class="nt">input_csv_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/FABind/inference/fabind_${dataset}_inputs.csv</span><span class="w"> </span><span class="c1"># the input CSV filepath with which to run inference</span>
<span class="nt">input_data_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/data/${dataset}_set/${dataset}_holo_aligned_esmfold_structures</span><span class="w"> </span><span class="c1"># the input protein-ligand complex directory to recursively parse</span>
<span class="nt">num_threads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the number of threads to use for inference</span>
<span class="nt">save_pt_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/FABind/inference/fabind_${dataset}_temp_files</span><span class="w"> </span><span class="c1"># a temporary directory in which to save the intermediate PyTorch tensors</span>
<span class="nt">save_mols_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/FABind/inference/fabind_${dataset}_temp_files/mol</span><span class="w"> </span><span class="c1"># a temporary directory in which to save the intermediate RDKit molecules</span>
<span class="nt">ckpt_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/FABind/ckpt/best_model.bin</span><span class="w"> </span><span class="c1"># the checkpoint path to use for inference</span>
<span class="nt">output_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/FABind/inference/fabind_${dataset}_output_${repeat_index}</span><span class="w"> </span><span class="c1"># the output directory to which to save the inference results</span>
<span class="nt">repeat_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the repeat index to use for inference</span>
<span class="nt">pocket_only_baseline</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to run the pocket-only baseline</span>
<span class="nt">max_num_inputs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># if provided, the number of (dataset subset) inputs over which to run inference</span>
</pre></div>
</div>
</div>
</section>
<section id="dynamicbind-inference">
<h3>DynamicBind inference<a class="headerlink" href="#dynamicbind-inference" title="Link to this heading">¶</a></h3>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text"><code class="file docutils literal notranslate"><span class="pre">model/dynamicbind_inference.yaml</span></code></span><a class="headerlink" href="#id3" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">cuda_device_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the CUDA device to use for inference, or `null` to use CPU</span>
<span class="nt">python_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DynamicBind/DynamicBind/bin/python3</span><span class="w"> </span><span class="c1"># the Python executable to use</span>
<span class="nt">dynamicbind_exec_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DynamicBind</span><span class="w"> </span><span class="c1"># the DynamicBind directory in which to execute the inference scripts</span>
<span class="nt">dataset</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">posebusters_benchmark</span><span class="w"> </span><span class="c1"># the dataset to use - NOTE: must be one of (`posebusters_benchmark`, `astex_diverse`, `dockgen`, `casp15`)</span>
<span class="nt">input_data_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/data/${dataset}_set/${dataset}_holo_aligned_esmfold_structures</span><span class="w"> </span><span class="c1"># the input protein-ligand complex directory to recursively parse for protein inputs</span>
<span class="nt">input_ligand_csv_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DynamicBind/inference/dynamicbind_${dataset}_inputs</span><span class="w"> </span><span class="c1"># the input CSV directory with which to run inference</span>
<span class="nt">samples_per_complex</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40</span><span class="w"> </span><span class="c1"># the number of samples to generate per complex</span>
<span class="nt">savings_per_complex</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the (top-N) number of sample visualizations to save per complex</span>
<span class="nt">inference_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20</span><span class="w"> </span><span class="c1"># the number of inference steps to run for each complex</span>
<span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span><span class="w"> </span><span class="c1"># the batch size to use for inference</span>
<span class="nt">header</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${dataset}</span><span class="w"> </span><span class="c1"># name of the results directory to create</span>
<span class="nt">num_workers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the number of workers to use for native relaxation during inference</span>
<span class="nt">skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to skip existing predictions</span>
<span class="nt">repeat_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the repeat index to use for inference</span>
<span class="nt">pocket_only_baseline</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to run the pocket-only baseline</span>
<span class="nt">max_num_inputs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># if provided, the number of (dataset subset) inputs over which to run inference</span>
</pre></div>
</div>
</div>
</section>
<section id="neuralplexer-inference">
<h3>NeuralPLexer inference<a class="headerlink" href="#neuralplexer-inference" title="Link to this heading">¶</a></h3>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text"><code class="file docutils literal notranslate"><span class="pre">model/neuralplexer_inference.yaml</span></code></span><a class="headerlink" href="#id4" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">python_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/NeuralPLexer/NeuralPLexer/bin/python3</span><span class="w"> </span><span class="c1"># the Python executable to use</span>
<span class="nt">neuralplexer_exec_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/NeuralPLexer</span><span class="w"> </span><span class="c1"># the NeuralPLexer directory in which to execute the inference scripts</span>
<span class="nt">dataset</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">posebusters_benchmark</span><span class="w"> </span><span class="c1"># the dataset to use - NOTE: must be one of (`posebusters_benchmark`, `astex_diverse`, `dockgen`, `casp15`)</span>
<span class="nt">input_csv_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/NeuralPLexer/inference/neuralplexer_${dataset}_inputs.csv</span><span class="w"> </span><span class="c1"># the input CSV filepath to which parsed input data has been written</span>
<span class="nt">skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to skip existing predictions</span>
<span class="nt">task</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">batched_structure_sampling</span><span class="w"> </span><span class="c1"># the task to run - NOTE: must be one of (`single_sample_trajectory`, `batched_structure_sampling`, `structure_prediction_benchmarking`, `pdbbind_benchmarking`, `binding_site_recovery_benchmarking`)</span>
<span class="nt">sample_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the sample ID to use for inference</span>
<span class="nt">template_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the template ID to use for inference</span>
<span class="nt">cuda_device_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the CUDA device to use for inference, or `null` to use CPU</span>
<span class="nt">model_checkpoint</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/NeuralPLexer/neuralplexermodels_downstream_datasets_predictions/models/complex_structure_prediction.ckpt</span><span class="w"> </span><span class="c1"># the model checkpoint to use for inference</span>
<span class="nt">out_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/NeuralPLexer/inference/neuralplexer_${dataset}_outputs_${repeat_index}</span><span class="w"> </span><span class="c1"># the output directory to which to write the predictions</span>
<span class="nt">n_samples</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40</span><span class="w"> </span><span class="c1"># the number of conformations to generate per complex</span>
<span class="nt">chunk_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w"> </span><span class="c1"># the number of conformations to generate in parallel per complex</span>
<span class="nt">num_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40</span><span class="w"> </span><span class="c1"># the number of steps to take in the sampling process</span>
<span class="nt">latent_model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># which type of latent model to use - NOTE: must be one of (`null`)</span>
<span class="nt">sampler</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">langevin_simulated_annealing</span><span class="w"> </span><span class="c1"># the sampler to use - NOTE: must be one of (`DDIM`, `VPSDE`, `simulated_annealing_simple`, `langevin_simulated_annealing`)</span>
<span class="nt">start_time</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;1.0&quot;</span><span class="w"> </span><span class="c1"># the start time at which to start sampling - NOTE: must be a string representation of a float</span>
<span class="nt">max_chain_encoding_k</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-1</span><span class="w"> </span><span class="c1"># the maximum chain encoding `k` to use</span>
<span class="nt">exact_prior</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to use the exact prior</span>
<span class="nt">discard_ligand</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to discard the ligand</span>
<span class="nt">discard_sdf_coords</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to discard the SDF coordinates</span>
<span class="nt">detect_covalent</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to detect covalent bonds</span>
<span class="nt">use_template</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to use the input template protein structure</span>
<span class="nt">separate_pdb</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to separate the predicted protein structures into dedicated PDB files</span>
<span class="nt">rank_outputs_by_confidence</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to rank the output conformations, by default, by ligand confidence (if available) and by protein confidence otherwise</span>
<span class="nt">plddt_ranking_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ligand</span><span class="w"> </span><span class="c1"># the type of plDDT ranking to apply to generated samples - NOTE: must be one of (`protein`, `ligand`, `protein_ligand`)</span>
<span class="nt">csv_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the CSV filepath from which to parse benchmarking input data</span>
<span class="nt">repeat_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the repeat index to use for inference</span>
<span class="nt">max_num_inputs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># if provided, the number of (dataset subset) inputs over which to run inference</span>
</pre></div>
</div>
</div>
</section>
<section id="rosettafold-all-atom-inference">
<h3>RoseTTAFold-All-Atom inference<a class="headerlink" href="#rosettafold-all-atom-inference" title="Link to this heading">¶</a></h3>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text"><code class="file docutils literal notranslate"><span class="pre">model/rfaa_inference.yaml</span></code></span><a class="headerlink" href="#id5" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">python_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/RoseTTAFold-All-Atom/RFAA/bin/python3</span><span class="w"> </span><span class="c1"># the Python executable to use</span>
<span class="nt">rfaa_exec_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/RoseTTAFold-All-Atom</span><span class="w"> </span><span class="c1"># the RoseTTAFold-All-Atom directory in which to execute the inference scripts</span>
<span class="nt">dataset</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">posebusters_benchmark</span><span class="w"> </span><span class="c1"># the dataset to use - NOTE: must be one of (`posebusters_benchmark`, `astex_diverse`, `dockgen`, `casp15`)</span>
<span class="nt">input_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/RoseTTAFold-All-Atom/prediction_inputs/${dataset}</span><span class="w"> </span><span class="c1"># the input directory with which to run inference</span>
<span class="nt">config_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/RoseTTAFold-All-Atom/rf2aa/config/inference</span><span class="w"> </span><span class="c1"># the config directory with which to run inference</span>
<span class="nt">output_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/RoseTTAFold-All-Atom/prediction_outputs/${dataset}_${repeat_index}</span><span class="w"> </span><span class="c1"># the output directory to which to save the inference results</span>
<span class="nt">max_cycles</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w"> </span><span class="c1"># the maximum number of recycling iterations to run</span>
<span class="nt">cuda_device_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the CUDA device to use for inference, or `null` to use CPU</span>
<span class="nt">run_inference_directly</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to run the inference code directly (true) or to rely on the user to run the generated scripts manually (false)</span>
<span class="nt">inference_config_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the name of the inference config to use - NOTE: if `run_inference_directly` is true, this must reference a valid YAML config file name e.g., that was generated by `python multicom_ligand/models/rfaa_inference.py` with `run_inference_directly=false`</span>
<span class="nt">inference_dir_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the name of the inference output directory to use</span>
<span class="nt">repeat_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the repeat index to use for inference</span>
<span class="nt">skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to skip running inference if the prediction for a target already exists</span>
<span class="nt">max_num_inputs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># if provided, the number of (dataset subset) inputs over which to run inference</span>
</pre></div>
</div>
</div>
</section>
<section id="vina-inference">
<h3>Vina inference<a class="headerlink" href="#vina-inference" title="Link to this heading">¶</a></h3>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text"><code class="file docutils literal notranslate"><span class="pre">model/vina_inference.yaml</span></code></span><a class="headerlink" href="#id6" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">dataset</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">posebusters_benchmark</span><span class="w"> </span><span class="c1"># the dataset to use - NOTE: must be one of (`posebusters_benchmark`, `astex_diverse`, `dockgen`, `casp15`)</span>
<span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">diffdock</span><span class="w"> </span><span class="c1"># the method from which to use binding site predictions - NOTE: must be one of (`diffdock`, `dynamicbind`, `neuralplexer`, `p2rank`, `ensemble`) - NOTE: `p2rank` is not included in `ensemble`</span>
<span class="nt">ensemble_ranking_method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">consensus</span><span class="w"> </span><span class="c1"># the method with which to rank-order and select the top ensemble prediction for each target - NOTE: must be one of (`consensus`, `ff`)</span>
<span class="nt">python2_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/Vina/ADFR/bin/python</span><span class="w"> </span><span class="c1"># the path to the Python 2 executable</span>
<span class="nt">p2rank_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/P2Rank/p2rank_2.4.2/prank</span><span class="w"> </span><span class="c1"># the path to the P2Rank executable</span>
<span class="nt">prepare_receptor_script_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/Vina/ADFR/CCSBpckgs/AutoDockTools/Utilities24/prepare_receptor4.py</span><span class="w"> </span><span class="c1"># the path to the prepare_receptor.py script</span>
<span class="nt">input_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${resolve_method_output_dir:${method},${dataset},${method},${ensemble_ranking_method},${repeat_index}}</span><span class="w"> </span><span class="c1"># the input directory with which to run inference</span>
<span class="nt">input_protein_structure_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/data/${dataset}_set/${dataset}_holo_aligned_esmfold_structures</span><span class="w"> </span><span class="c1"># the input protein structure directory to parse</span>
<span class="nt">output_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/data/test_cases/${dataset}/vina_${method}_${dataset}_outputs_${repeat_index}</span><span class="w"> </span><span class="c1"># the output directory to which to save the inference results</span>
<span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the number of CPU workers to use with AutoDock Vina for parallel processing, 0 for all available</span>
<span class="nt">seed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the random seed to use with AutoDock Vina</span>
<span class="nt">exhaustiveness</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">32</span><span class="w"> </span><span class="c1"># the exhaustiveness to use with AutoDock Vina</span>
<span class="nt">ligand_ligand_distance_threshold</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">25.0</span><span class="w"> </span><span class="c1"># the distance threshold (in Angstrom) to use for finding shared binding sites amongst ligands</span>
<span class="nt">protein_ligand_distance_threshold</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4.0</span><span class="w"> </span><span class="c1"># the heavy-atom distance threshold (in Angstrom) to use for finding protein binding sites amongst grouped ligands</span>
<span class="nt">binding_site_size_x</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">25.0</span><span class="w"> </span><span class="c1"># the x-axis size of the binding site box to use with AutoDock Vina</span>
<span class="nt">binding_site_size_y</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">25.0</span><span class="w"> </span><span class="c1"># the y-axis size of the binding site box to use with AutoDock Vina</span>
<span class="nt">binding_site_size_z</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">25.0</span><span class="w"> </span><span class="c1"># the z-axis size of the binding site box to use with AutoDock Vina</span>
<span class="nt">binding_site_spacing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span><span class="w"> </span><span class="c1"># the spacing of the binding site box (in Angstrom) to use with AutoDock Vina</span>
<span class="nt">num_modes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40</span><span class="w"> </span><span class="c1"># the number of binding modes (i.e., poses) to generate with AutoDock Vina</span>
<span class="nt">skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to skip existing output files</span>
<span class="nt">protein_filepath</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the protein file path to use for inference</span>
<span class="nt">ligand_filepaths</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the ligand file paths to use for inference</span>
<span class="nt">apo_protein_filepath</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the apo protein file path to use for inference</span>
<span class="nt">input_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the input ID to use for inference</span>
<span class="nt">repeat_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the repeat index to use for inference</span>
<span class="nt">pocket_only_baseline</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to run the pocket-only baseline</span>
<span class="nt">p2rank_exec_utility</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">predict</span><span class="w"> </span><span class="c1"># the P2Rank executable utility to use for inference</span>
<span class="nt">p2rank_config</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">alphafold</span><span class="w"> </span><span class="c1"># the P2Rank configuration to use for inference</span>
<span class="nt">p2rank_enable_pymol_visualizations</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to enable P2Rank&#39;s PyMOL visualizations</span>
<span class="nt">max_num_inputs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># if provided, the number of (dataset subset) inputs over which to run inference</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="ensemble-inference">
<h2>Ensemble inference<a class="headerlink" href="#ensemble-inference" title="Link to this heading">¶</a></h2>
<p>This configuration is used to specify how inference is performed with a method ensemble (e.g., via <cite>consensus</cite> ranking).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This script not only enables inference with a method ensemble, but it also provides a unified wrapper with which one
can relax and structure a method’s predictions in a CASP-compliant file format for scoring.</p>
</div>
<section id="ensemble-generation">
<h3>Ensemble generation<a class="headerlink" href="#ensemble-generation" title="Link to this heading">¶</a></h3>
<div class="literal-block-wrapper docutils container" id="id7">
<div class="code-block-caption"><span class="caption-text"><code class="file docutils literal notranslate"><span class="pre">model/ensemble_generation.yaml</span></code></span><a class="headerlink" href="#id7" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">ensemble_methods</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span>
<span class="w">    </span><span class="nv">diffdock</span><span class="p p-Indicator">,</span>
<span class="w">    </span><span class="nv">dynamicbind</span><span class="p p-Indicator">,</span>
<span class="w">    </span><span class="nv">neuralplexer</span><span class="p p-Indicator">,</span>
<span class="w">    </span><span class="nv">flowdock</span><span class="p p-Indicator">,</span>
<span class="w">    </span><span class="nv">rfaa</span><span class="p p-Indicator">,</span>
<span class="w">    </span><span class="nv">vina</span><span class="p p-Indicator">,</span>
<span class="w">    </span><span class="nv">tulip</span><span class="p p-Indicator">,</span>
<span class="w">  </span><span class="p p-Indicator">]</span><span class="w"> </span><span class="c1"># the methods from which to gather predictions for ensembling - NOTE: must be one of (`diffdock`, `dynamicbind`, `neuralplexer`, `flowdock`, `rfaa`, `vina`, `tulip`)</span>
<span class="nt">generate_vina_scripts</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to generate Vina scripts using other methods&#39; binding site predictions - NOTE: `resume` must also be `true` when this is `true`, meaning other methods&#39; predictions must have already been generated locally</span>
<span class="nt">rank_single_method_intrinsically</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to rank single-method predictions using either `consensus` or `vina` ranking (false) or instead using their intrinsic (explicit) rank assignment (true)</span>
<span class="nt">output_bash_file_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ensemble_generation_scripts</span><span class="w"> </span><span class="c1"># the directory in which to save the generated Bash scripts</span>
<span class="nt">cuda_device_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the CUDA device to use for inference, or `null` to use CPU</span>
<span class="nt">input_csv_filepath</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/data/test_cases/5S8I_2LY/ensemble_inputs.csv</span><span class="w"> </span><span class="c1"># path to a CSV file containing the following columns: `protein_input`, `ligand_smiles`, `name`</span>
<span class="nt">temp_protein_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/data/ensemble_proteins</span><span class="w"> </span><span class="c1"># directory path to which to save temporary predicted protein structures</span>
<span class="nt">structure_prediction_script_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/multicom_ligand/data/components/esmfold_batch_structure_prediction.py</span><span class="w"> </span><span class="c1"># path to the ESMFold structure prediction script to use</span>
<span class="nt">structure_prediction_chunk_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># optional chunk size to use during ESMFold structure prediction to reduce memory requirements</span>
<span class="nt">structure_prediction_cpu_only</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to only use CPU for structure prediction</span>
<span class="nt">structure_prediction_cpu_offload</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to offload structure prediction to CPU</span>
<span class="nt">max_method_predictions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40</span><span class="w"> </span><span class="c1"># maximum number of predictions to make with each method</span>
<span class="nt">method_top_n_to_select</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${max_method_predictions}</span><span class="w"> </span><span class="c1"># number of top-ranked predictions to select from each method for subsequent ranking</span>
<span class="nt">skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to skip existing ensemble predictions</span>
<span class="nt">relax_method_ligands_pre_ranking</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to relax the predicted ligands (method-specifically) before ranking</span>
<span class="nt">relax_method_ligands_post_ranking</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to relax the predicted ligands (method-agnostically) after ranking</span>
<span class="nt">relax_add_solvent</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to add solvent during relaxation</span>
<span class="nt">relax_prep_only</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># only prepare the input files for relaxation</span>
<span class="nt">relax_platform</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;fastest&quot;</span><span class="w"> </span><span class="c1"># platform on which to run relaxation</span>
<span class="nt">relax_log_level</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;INFO&quot;</span><span class="w"> </span><span class="c1"># logging level for relaxation</span>
<span class="nt">relax_protein</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to relax the protein</span>
<span class="nt">relax_remove_initial_protein_hydrogens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to remove hydrogens from the initial protein</span>
<span class="nt">relax_assign_each_ligand_unique_force</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to assign each ligand a unique force constant</span>
<span class="nt">relax_model_ions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to model ions</span>
<span class="nt">relax_cache_files</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to cache the prepared relaxation files</span>
<span class="nt">relax_assign_partial_charges_manually</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to assign partial charges manually</span>
<span class="nt">relax_max_final_e_value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000.0</span><span class="w"> </span><span class="c1"># when relaxing the protein, maximum final energy value to permit</span>
<span class="nt">relax_max_num_attempts</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span><span class="w"> </span><span class="c1"># when relaxing the protein, maximum number of relaxation attempts to perform</span>
<span class="nt">relax_num_processes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># number of processes to use for relaxation</span>
<span class="nt">relax_skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to skip existing relaxation results</span>
<span class="nt">resume</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to resume from a previous run after generating and manually running each method&#39;s prediction script</span>
<span class="nt">input_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># optional path to the directory from which to load the ensemble predictions to rank - NOTE: currently, only `neuralplexer` makes use of this for inference output parsing</span>
<span class="nt">output_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/data/test_cases/5S8I_2LY/top_${ensemble_ranking_method}_ensemble_predictions</span><span class="w"> </span><span class="c1"># path to the directory to save the top-ranked ensemble predictions</span>
<span class="nt">export_file_format</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">casp16</span><span class="w"> </span><span class="c1"># if not `null`, the CASP format (i.e., `casp15` or `casp16`) in which to export top-ranked predictions</span>
<span class="nt">export_top_n</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span><span class="w"> </span><span class="c1"># number of top-ranked predictions to export in CASP format</span>
<span class="nt">rerank_multi_ligand_predictions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to rerank multi-ligand predictions to favor structures from a preferred multi-ligand structure generation method</span>
<span class="nt">preferred_multi_ligand_method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">neuralplexer</span><span class="w"> </span><span class="c1"># the preferred multi-ligand structure generation method - NOTE: must be one of (`neuralplexer`, `flowdock`)</span>
<span class="nt">rerank_clashing_predictions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to rank-downgrade CASP predictions with protein residue-residue steric clashes after initial ranking</span>
<span class="nt">casp_author</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;001&quot;</span><span class="w"> </span><span class="c1"># group number to report in CASP format</span>
<span class="nt">casp_registration_code</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;1234-5678-9012&quot;</span><span class="w"> </span><span class="c1"># registration code of the prediction group to list in CASP format</span>
<span class="nt">casp_method</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Ligand_Predictor&quot;</span><span class="w"> </span><span class="c1"># the method name to report in CASP format</span>
<span class="nt">combine_casp_output_files</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to combine the CASP protein and ligand output files into a single file</span>
<span class="nt">generate_hpc_scripts</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to generate HPC scripts for running the ensemble generation; if `false`, then local scripts will be generated instead</span>
<span class="nt">pocket_only_baseline</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to run ensemble generation with only pocket-based baseline methods</span>
<span class="nt">superligand_inputs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether CASP16 superligand inputs are requested for ensemble generation, which are handled differently from standard CASP16 ligand targets in terms of output file formatting</span>
<span class="nt">ensemble_benchmarking</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to run ensemble benchmarking</span>
<span class="nt">ensemble_benchmarking_dataset</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">posebusters_benchmark</span><span class="w"> </span><span class="c1"># the dataset to use for ensemble benchmarking - NOTE: must be one of (`posebusters_benchmark`, `astex_diverse`, `dockgen`, `casp15`)</span>
<span class="nt">ensemble_benchmarking_repeat_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the repeat index to use for ensemble benchmarking</span>
<span class="nt">ensemble_ranking_method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">consensus</span><span class="w"> </span><span class="c1"># the method with which to rank-order and select the top ensemble prediction for each target - NOTE: must be one of (`consensus`, `ff`)</span>
<span class="nt">ensemble_benchmarking_apo_protein_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/data/${ensemble_benchmarking_dataset}_set/${ensemble_benchmarking_dataset}_holo_aligned_esmfold_structures</span><span class="w"> </span><span class="c1"># the directory containing the apo proteins to use for ensemble benchmarking</span>
<span class="c1"># DiffDock inference arguments:</span>
<span class="nt">diffdock_python_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock/DiffDock/bin/python3</span><span class="w"> </span><span class="c1"># the Python executable to use</span>
<span class="nt">diffdock_exec_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock</span><span class="w"> </span><span class="c1"># the DiffDock directory in which to execute the inference scripts</span>
<span class="nt">diffdock_input_csv_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock/inference/diffdock_ensemble_inputs.csv</span><span class="w"> </span><span class="c1"># the input CSV filepath with which to run inference</span>
<span class="nt">diffdock_inference_config_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock/default_inference_args.yaml</span><span class="w"> </span><span class="c1"># the inference configuration file to use</span>
<span class="nt">diffdock_output_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock/inference/diffdock_ensemble_output</span><span class="w"> </span><span class="c1"># the output directory to which to save the inference results</span>
<span class="nt">diffdock_model_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock/workdir/v1.1/score_model</span><span class="w"> </span><span class="c1"># the directory in which the trained model is saved</span>
<span class="nt">diffdock_confidence_model_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DiffDock/workdir/v1.1/confidence_model</span><span class="w"> </span><span class="c1"># the directory in which the trained confidence model is saved</span>
<span class="nt">diffdock_inference_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20</span><span class="w"> </span><span class="c1"># the maximum number of inference (reverse diffusion) steps to run</span>
<span class="nt">diffdock_samples_per_complex</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${max_method_predictions}</span><span class="w"> </span><span class="c1"># the number of samples to generate per complex</span>
<span class="nt">diffdock_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w"> </span><span class="c1"># the batch size to use for inference</span>
<span class="nt">diffdock_actual_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">19</span><span class="w"> </span><span class="c1"># the actual number of inference steps to run (i.e., after how many steps to halt the reverse diffusion process)</span>
<span class="nt">diffdock_no_final_step_noise</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to disable the final inference step&#39;s noise from being added</span>
<span class="nt">diffdock_skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to skip existing predictions</span>
<span class="nt">diffdock_validate_target_names</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to validate the (protein and ligand file) target names with respect to the input CSV</span>
<span class="c1"># DynamicBind inference arguments:</span>
<span class="nt">dynamicbind_python_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DynamicBind/DynamicBind/bin/python3</span><span class="w"> </span><span class="c1"># the Python executable to use</span>
<span class="nt">dynamicbind_exec_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DynamicBind</span><span class="w"> </span><span class="c1"># the DynamicBind directory in which to execute the inference scripts</span>
<span class="nt">dynamicbind_dataset</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ensemble</span><span class="w"> </span><span class="c1"># the dataset to use for inference - NOTE: must be one of (`ensemble`)</span>
<span class="nt">dynamicbind_input_protein_data_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DynamicBind/inference/ensemble_esmfold_structures</span><span class="w"> </span><span class="c1"># the input protein-ligand complex directory to recursively parse for protein inputs</span>
<span class="nt">dynamicbind_input_ligand_csv_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/DynamicBind/inference/dynamicbind_ensemble_inputs</span><span class="w"> </span><span class="c1"># the input CSV directory with which to run inference</span>
<span class="nt">dynamicbind_samples_per_complex</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40</span><span class="w"> </span><span class="c1"># the number of samples to generate per complex</span>
<span class="nt">dynamicbind_savings_per_complex</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the (top-N) number of sample visualizations to save per complex</span>
<span class="nt">dynamicbind_inference_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20</span><span class="w"> </span><span class="c1"># the number of inference steps to run for each complex</span>
<span class="nt">dynamicbind_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span><span class="w"> </span><span class="c1"># the batch size to use for inference</span>
<span class="nt">dynamicbind_header</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ensemble</span><span class="w"> </span><span class="c1"># name of the results directory to create</span>
<span class="nt">dynamicbind_num_workers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the number of workers to use for native relaxation during inference</span>
<span class="nt">dynamicbind_skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to skip existing predictions</span>
<span class="c1"># NeuralPLexer inference arguments:</span>
<span class="nt">neuralplexer_python_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/NeuralPLexer/NeuralPLexer/bin/python3</span><span class="w"> </span><span class="c1"># the Python executable to use</span>
<span class="nt">neuralplexer_exec_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/NeuralPLexer</span><span class="w"> </span><span class="c1"># the NeuralPLexer directory in which to execute the inference scripts</span>
<span class="nt">neuralplexer_input_data_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the input protein-ligand complex directory to recursively parse</span>
<span class="nt">neuralplexer_input_receptor_structure_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># if not `null`, the input template protein structure directory to parse</span>
<span class="nt">neuralplexer_input_csv_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/NeuralPLexer/inference/neuralplexer_ensemble_inputs.csv</span><span class="w"> </span><span class="c1"># the input CSV filepath with which to run inference</span>
<span class="nt">neuralplexer_skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to skip existing predictions</span>
<span class="nt">neuralplexer_task</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">batched_structure_sampling</span><span class="w"> </span><span class="c1"># the task to run - NOTE: must be one of (`single_sample_trajectory`, `batched_structure_sampling`, `structure_prediction_benchmarking`, `pdbbind_benchmarking`, `binding_site_recovery_benchmarking`)</span>
<span class="nt">neuralplexer_sample_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the sample ID to use for inference</span>
<span class="nt">neuralplexer_template_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the template ID to use for inference</span>
<span class="nt">neuralplexer_model_checkpoint</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/NeuralPLexer/neuralplexermodels_downstream_datasets_predictions/models/complex_structure_prediction.ckpt</span><span class="w"> </span><span class="c1"># the model checkpoint to use for inference</span>
<span class="nt">neuralplexer_out_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/NeuralPLexer/inference/neuralplexer_ensemble_outputs</span><span class="w"> </span><span class="c1"># the output directory to which to write the predictions</span>
<span class="nt">neuralplexer_n_samples</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40</span><span class="w"> </span><span class="c1"># the number of conformations to generate per complex</span>
<span class="nt">neuralplexer_chunk_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w"> </span><span class="c1"># the number of conformations to generate in parallel per complex</span>
<span class="nt">neuralplexer_num_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40</span><span class="w"> </span><span class="c1"># the number of steps to take in the sampling process</span>
<span class="nt">neuralplexer_sampler</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">langevin_simulated_annealing</span><span class="w"> </span><span class="c1"># the sampler to use - NOTE: must be one of (`DDIM`, `VPSDE`, `simulated_annealing_simple`, `langevin_simulated_annealing`)</span>
<span class="nt">neuralplexer_start_time</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;1.0&quot;</span><span class="w"> </span><span class="c1"># the start time at which to start sampling - NOTE: must be a string representation of a float</span>
<span class="nt">neuralplexer_max_chain_encoding_k</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-1</span><span class="w"> </span><span class="c1"># the maximum chain encoding `k` to use</span>
<span class="nt">neuralplexer_exact_prior</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to use the exact prior</span>
<span class="nt">neuralplexer_discard_ligand</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to discard the ligand</span>
<span class="nt">neuralplexer_discard_sdf_coords</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to discard the SDF coordinates</span>
<span class="nt">neuralplexer_detect_covalent</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to detect covalent bonds</span>
<span class="nt">neuralplexer_use_template</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to use the input template protein structure</span>
<span class="nt">neuralplexer_separate_pdb</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to separate the predicted protein structures into dedicated PDB files</span>
<span class="nt">neuralplexer_rank_outputs_by_confidence</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to rank the output conformations, by default, by ligand confidence (if available) and by protein confidence otherwise</span>
<span class="nt">neuralplexer_plddt_ranking_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ligand</span><span class="w"> </span><span class="c1"># the type of plDDT ranking to apply to generated samples - NOTE: must be one of (`protein`, `ligand`, `protein_ligand`)</span>
<span class="c1"># FlowDock inference arguments:</span>
<span class="nt">flowdock_python_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/FlowDock/FlowDock/bin/python3</span><span class="w"> </span><span class="c1"># the Python executable to use</span>
<span class="nt">flowdock_exec_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/FlowDock</span><span class="w"> </span><span class="c1"># the FlowDock directory in which to execute the inference scripts</span>
<span class="nt">flowdock_input_data_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the input protein-ligand complex directory to recursively parse</span>
<span class="nt">flowdock_input_receptor_structure_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># if not `null`, the input template protein structure directory to parse</span>
<span class="nt">flowdock_input_csv_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/FlowDock/inference/flowdock_ensemble_inputs.csv</span><span class="w"> </span><span class="c1"># the input CSV filepath with which to run inference</span>
<span class="nt">flowdock_skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to skip existing predictions</span>
<span class="nt">flowdock_sampling_task</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">batched_structure_sampling</span><span class="w"> </span><span class="c1"># the task to run - NOTE: must be one of (`batched_structure_sampling`)</span>
<span class="nt">flowdock_sample_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the sample ID to use for inference</span>
<span class="nt">flowdock_model_checkpoint</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/FlowDock/checkpoints/best_ep_d8ef2baz_epoch_189.ckpt</span><span class="w"> </span><span class="c1"># the model checkpoint to use for inference</span>
<span class="nt">flowdock_out_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/FlowDock/inference/flowdock_ensemble_outputs</span><span class="w"> </span><span class="c1"># the output directory to which to write the predictions</span>
<span class="nt">flowdock_n_samples</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40</span><span class="w"> </span><span class="c1"># the number of conformations to generate per complex</span>
<span class="nt">flowdock_chunk_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w"> </span><span class="c1"># the number of conformations to generate in parallel per complex</span>
<span class="nt">flowdock_num_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40</span><span class="w"> </span><span class="c1"># the number of steps to take in the sampling process</span>
<span class="nt">flowdock_latent_model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># which type of latent model to use - NOTE: must be one of (`null`)</span>
<span class="nt">flowdock_sampler</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">VDODE</span><span class="w"> </span><span class="c1"># sampling algorithm to use - NOTE: must be one of (`ODE`, `VDODE`)</span>
<span class="nt">flowdock_sampler_eta</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span><span class="w"> </span><span class="c1"># the variance diminishing factor for the `VDODE` sampler - NOTE: offers a trade-off between exploration (1.0) and exploitation (&gt; 1.0)</span>
<span class="nt">flowdock_start_time</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;1.0&quot;</span><span class="w"> </span><span class="c1"># the start time at which to start sampling - NOTE: must be a string representation of a float</span>
<span class="nt">flowdock_max_chain_encoding_k</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-1</span><span class="w"> </span><span class="c1"># the maximum chain encoding `k` to use</span>
<span class="nt">flowdock_exact_prior</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to use the exact prior</span>
<span class="nt">flowdock_discard_ligand</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to discard the ligand</span>
<span class="nt">flowdock_discard_sdf_coords</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to discard the SDF coordinates</span>
<span class="nt">flowdock_detect_covalent</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to detect covalent bonds</span>
<span class="nt">flowdock_use_template</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to use the input template protein structure</span>
<span class="nt">flowdock_separate_pdb</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to separate the predicted protein structures into dedicated PDB files</span>
<span class="nt">flowdock_rank_outputs_by_confidence</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to rank the output conformations, by default, by ligand confidence (if available) and by protein confidence otherwise</span>
<span class="nt">flowdock_plddt_ranking_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ligand</span><span class="w"> </span><span class="c1"># the type of plDDT ranking to apply to generated samples - NOTE: must be one of (`protein`, `ligand`, `protein_ligand`)</span>
<span class="nt">flowdock_visualize_sample_trajectories</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to visualize the generated samples&#39; trajectories</span>
<span class="nt">flowdock_auxiliary_estimation_only</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to only estimate auxiliary outputs (e.g., confidence, affinity) for the input (generated) samples (potentially derived from external sources)</span>
<span class="nt">flowdock_auxiliary_estimation_input_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># if provided, an input directory of subdirectories (named according to target IDs) of PDB-SDF file pairs (potentially derived from external sources) for which to estimate auxiliary outputs (e.g., confidence, affinity) and for which to represent the outputs as a rank-ordered CSV file within the same subdirectory</span>
<span class="nt">flowdock_esmfold_chunk_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># chunks axial attention computation to reduce memory usage from O(L^2) to O(L); equivalent to running a for loop over chunks of of each dimension; lower values will result in lower memory usage at the cost of speed; recommended values: 128, 64, 32</span>
<span class="c1"># RoseTTAFold-All-Atom inference arguments:</span>
<span class="nt">rfaa_python_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/RoseTTAFold-All-Atom/RFAA/bin/python3</span><span class="w"> </span><span class="c1"># the Python executable to use</span>
<span class="nt">rfaa_exec_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/RoseTTAFold-All-Atom</span><span class="w"> </span><span class="c1"># the RoseTTAFold-All-Atom directory in which to execute the inference scripts</span>
<span class="nt">rfaa_config_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/RoseTTAFold-All-Atom/rf2aa/config/inference</span><span class="w"> </span><span class="c1"># the config directory with which to run inference</span>
<span class="nt">rfaa_output_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/RoseTTAFold-All-Atom/inference/rfaa_ensemble_outputs</span><span class="w"> </span><span class="c1"># the output directory to which to save the inference results</span>
<span class="nt">rfaa_max_cycles</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w"> </span><span class="c1"># the maximum number recycling iterations to run</span>
<span class="nt">rfaa_inference_config_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the name of the inference config to use - NOTE: if `run_inference_directly` is true, this must reference a valid YAML config file name e.g., that was generated by `python multicom_ligand/models/rfaa_inference.py` with `run_inference_directly=false`</span>
<span class="nt">rfaa_inference_dir_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the name of the inference output directory to use</span>
<span class="c1"># Vina inference arguments:</span>
<span class="nt">vina_binding_site_methods</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">diffdock</span><span class="p p-Indicator">]</span><span class="w"> </span><span class="c1"># the methods to use for Vina binding site prediction - NOTE: must be one of (`diffdock`, `fabind`, `dynamicbind`, `neuralplexer`, `rfaa`)</span>
<span class="nt">vina_python2_exec_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/Vina/ADFR/bin/python</span><span class="w"> </span><span class="c1"># the path to the Python 2 executable</span>
<span class="nt">vina_prepare_receptor_script_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/Vina/ADFR/CCSBpckgs/AutoDockTools/Utilities24/prepare_receptor4.py</span><span class="w"> </span><span class="c1"># the path to the prepare_receptor.py script</span>
<span class="nt">vina_output_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/Vina/inference/vina_ensemble_outputs</span><span class="w"> </span><span class="c1"># the output directory to which to save the inference results</span>
<span class="nt">vina_cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># the number of CPU workers to use with AutoDock Vina for parallel processing, 0 for all available</span>
<span class="nt">vina_seed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># the random seed to use with AutoDock Vina</span>
<span class="nt">vina_exhaustiveness</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">32</span><span class="w"> </span><span class="c1"># the exhaustiveness to use with AutoDock Vina</span>
<span class="nt">vina_ligand_ligand_distance_threshold</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">25.0</span><span class="w"> </span><span class="c1"># the distance threshold (in Angstrom) to use for finding shared binding sites amongst ligands</span>
<span class="nt">vina_protein_ligand_distance_threshold</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10.0</span><span class="w"> </span><span class="c1"># the distance threshold (in Angstrom) to use for finding protein binding sites amongst grouped ligands</span>
<span class="nt">vina_binding_site_size_x</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">25.0</span><span class="w"> </span><span class="c1"># the x-axis size of the binding site box to use with AutoDock Vina</span>
<span class="nt">vina_binding_site_size_y</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">25.0</span><span class="w"> </span><span class="c1"># the y-axis size of the binding site box to use with AutoDock Vina</span>
<span class="nt">vina_binding_site_size_z</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">25.0</span><span class="w"> </span><span class="c1"># the z-axis size of the binding site box to use with AutoDock Vina</span>
<span class="nt">vina_binding_site_spacing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span><span class="w"> </span><span class="c1"># the spacing of the binding site box (in Angstrom) to use with AutoDock Vina</span>
<span class="nt">vina_num_modes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40</span><span class="w"> </span><span class="c1"># the number of binding modes (i.e., poses) to generate with AutoDock Vina</span>
<span class="nt">vina_skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to skip existing output files</span>
<span class="c1"># TULIP inference arguments:</span>
<span class="nt">tulip_output_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${oc.env:PROJECT_ROOT}/forks/TULIP/inference/tulip_ensemble_outputs</span><span class="w"> </span><span class="c1"># the output directory to which to save the inference results</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="structure-relaxation">
<h2>Structure relaxation<a class="headerlink" href="#structure-relaxation" title="Link to this heading">¶</a></h2>
<p>These configurations are used to specify how relaxation is (optionally) applied to a predicted protein-ligand complex structure using molecular dynamics (i.e., <a class="reference external" href="https://openmm.org">OpenMM</a>).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <cite>inference_relaxation</cite> configuration describes the behavior of the script that serves as an entry point for the relaxation process. The <cite>minimize_energy</cite> configuration is a multi-ligand generalization of the main energy minimization script originally implemented for the <a class="reference external" href="https://github.com/maabuu/posebusters_em">PoseBusters</a> software suite.</p>
</div>
<section id="inference-relaxation-entry-point">
<h3>Inference relaxation (entry point)<a class="headerlink" href="#inference-relaxation-entry-point" title="Link to this heading">¶</a></h3>
<div class="literal-block-wrapper docutils container" id="id8">
<div class="code-block-caption"><span class="caption-text"><code class="file docutils literal notranslate"><span class="pre">model/inference_relaxation.yaml</span></code></span><a class="headerlink" href="#id8" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">diffdock</span><span class="w"> </span><span class="c1"># the method for which to relax predictions - NOTE: must be one of (`diffdock`, `fabind`, `dynamicbind`, `neuralplexer`, `rfaa`, `vina`, `tulip`)</span>
<span class="nt">vina_binding_site_method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">diffdock</span><span class="w"> </span><span class="c1"># the method to use for Vina binding site prediction - NOTE: must be one of (`diffdock`, `fabind`, `dynamicbind`, `neuralplexer`, `rfaa`, `p2rank`)</span>
<span class="nt">dataset</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">posebusters_benchmark</span><span class="w"> </span><span class="c1"># the dataset for which to relax predictions - NOTE: must be one of (`posebusters_benchmark`, `astex_diverse`, `dockgen`, `casp15`)</span>
<span class="nt">ensemble_ranking_method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">consensus</span><span class="w"> </span><span class="c1"># the method with which to rank-order and select the top ensemble prediction for each target - NOTE: must be one of (`consensus`, `ff`)</span>
<span class="nt">num_processes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the number of parallel processes to use for relaxation</span>
<span class="nt">temp_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${method}_${dataset}_cache_dir</span><span class="w"> </span><span class="c1"># temporary directory</span>
<span class="nt">add_solvent</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to add solvent during relaxation</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># name of the relaxation target</span>
<span class="nt">prep_only</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># only prepare the input files</span>
<span class="nt">platform</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;fastest&quot;</span><span class="w"> </span><span class="c1"># platform on which to run relaxation</span>
<span class="nt">cuda_device_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># CUDA device index</span>
<span class="nt">log_level</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;INFO&quot;</span><span class="w"> </span><span class="c1"># logging level</span>
<span class="nt">protein_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${resolve_method_protein_dir:${method},${dataset},${repeat_index},${pocket_only_baseline}}</span><span class="w"> </span><span class="c1"># the directory from which to load (potentially inferred) proteins</span>
<span class="nt">ligand_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${resolve_method_ligand_dir:${method},${dataset},${vina_binding_site_method},${repeat_index}}</span><span class="w"> </span><span class="c1"># the directory from which to load inferred ligands</span>
<span class="nt">output_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${resolve_method_output_dir:${method},${dataset},${vina_binding_site_method},${ensemble_ranking_method},${repeat_index}}</span><span class="w"> </span><span class="c1"># the output directory to which to save the relaxed predictions</span>
<span class="nt">relax_protein</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to relax the protein - NOTE: currently periodically yields unpredictable protein-ligand separation</span>
<span class="nt">remove_initial_protein_hydrogens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to remove hydrogens from the initial protein</span>
<span class="nt">assign_each_ligand_unique_force</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># when relaxing the protein, whether to assign each ligand a unique force constant</span>
<span class="nt">model_ions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to model ions</span>
<span class="nt">cache_files</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to cache the prepared relaxation files</span>
<span class="nt">assign_partial_charges_manually</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to assign partial charges manually</span>
<span class="nt">report_initial_energy_only</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># skip relaxation and return only the initial energy of the complex structure</span>
<span class="nt">max_final_e_value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000.0</span><span class="w"> </span><span class="c1"># when relaxing the protein, maximum final energy value to permit</span>
<span class="nt">max_num_attempts</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span><span class="w"> </span><span class="c1"># when relaxing the protein, maximum number of relaxation attempts to perform</span>
<span class="nt">skip_existing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to skip existing relaxed predictions</span>
<span class="nt">repeat_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span><span class="c1"># the repeat index which was used for inference</span>
<span class="nt">pocket_only_baseline</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to prepare the pocket-only baseline</span>
</pre></div>
</div>
</div>
</section>
<section id="minimize-energy-relaxation-engine">
<h3>Minimize energy (relaxation engine)<a class="headerlink" href="#minimize-energy-relaxation-engine" title="Link to this heading">¶</a></h3>
<div class="literal-block-wrapper docutils container" id="id9">
<div class="code-block-caption"><span class="caption-text"><code class="file docutils literal notranslate"><span class="pre">model/minimize_energy.yaml</span></code></span><a class="headerlink" href="#id9" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">protein_file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">???</span><span class="w"> </span><span class="c1"># input protein file</span>
<span class="nt">ligand_file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">???</span><span class="w"> </span><span class="c1"># input ligand file</span>
<span class="nt">output_file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">???</span><span class="w"> </span><span class="c1"># ligand output file</span>
<span class="nt">protein_output_file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># optional protein output file</span>
<span class="nt">complex_output_file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># optional complex output file</span>
<span class="nt">temp_dir</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;cache_dir&quot;</span><span class="w"> </span><span class="c1"># temporary directory</span>
<span class="nt">add_solvent</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to add solvent during relaxation</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"> </span><span class="c1"># name of the relaxation target</span>
<span class="nt">prep_only</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># only prepare the input files</span>
<span class="nt">platform</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;fastest&quot;</span><span class="w"> </span><span class="c1"># platform on which to run relaxation</span>
<span class="nt">cuda_device_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1"># CUDA device index</span>
<span class="nt">log_level</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;INFO&quot;</span><span class="w"> </span><span class="c1"># logging level</span>
<span class="nt">relax_protein</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to relax the protein</span>
<span class="nt">remove_initial_protein_hydrogens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to remove hydrogens from the initial protein</span>
<span class="nt">assign_each_ligand_unique_force</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to assign each ligand a unique force constant</span>
<span class="nt">model_ions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to model ions</span>
<span class="nt">cache_files</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"> </span><span class="c1"># whether to cache the prepared relaxation files</span>
<span class="nt">assign_partial_charges_manually</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># whether to assign partial charges manually</span>
<span class="nt">report_initial_energy_only</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w"> </span><span class="c1"># skip relaxation and return only the initial energy of the complex structure</span>
<span class="nt">max_final_e_value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000.0</span><span class="w"> </span><span class="c1"># when relaxing the protein, maximum final energy value to permit</span>
<span class="nt">max_num_attempts</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span><span class="w"> </span><span class="c1"># when relaxing the protein, maximum number of relaxation attempts to perform</span>
</pre></div>
</div>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../modules/multicom_ligand.binding_site_crop_preparation.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Binding site crop preparation</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="data.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Data</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, Alex Morehead
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Model</a><ul>
<li><a class="reference internal" href="#method-inference">Method inference</a><ul>
<li><a class="reference internal" href="#diffdock-inference">DiffDock inference</a></li>
<li><a class="reference internal" href="#fabind-inference">FABind inference</a></li>
<li><a class="reference internal" href="#dynamicbind-inference">DynamicBind inference</a></li>
<li><a class="reference internal" href="#neuralplexer-inference">NeuralPLexer inference</a></li>
<li><a class="reference internal" href="#rosettafold-all-atom-inference">RoseTTAFold-All-Atom inference</a></li>
<li><a class="reference internal" href="#vina-inference">Vina inference</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ensemble-inference">Ensemble inference</a><ul>
<li><a class="reference internal" href="#ensemble-generation">Ensemble generation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#structure-relaxation">Structure relaxation</a><ul>
<li><a class="reference internal" href="#inference-relaxation-entry-point">Inference relaxation (entry point)</a></li>
<li><a class="reference internal" href="#minimize-energy-relaxation-engine">Minimize energy (relaxation engine)</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=6c02275b"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/tabs.js?v=3ee01567"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
    <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>